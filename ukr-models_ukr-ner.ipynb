{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0fff43a-15c5-46ec-ad5d-8b88f53ce032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: https://huggingface.co/ukr-models/uk-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c33167d-bb9e-4f40-972c-125966b06fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import torch\n",
    "import transformers\n",
    "import tokenize_uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c03ff733-5bd5-4f6f-805e-3e5128cb827d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2110685f-04db-495d-bd94-a6174387990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source:\n",
    "# https://blog.ehri-project.eu/uk/2023/05/05/the-holocaust-in-volhynia-uk/\n",
    "# some phrases were changed to test edge cases\n",
    "text = [\n",
    "    \"«У селі жили і поляки, і українці. Мамина рідна сестра вийшла заміж за поляка. Там вони живуть досі ті мої двоюрідні сестри. Батькові сестри також повиходили заміж за поляків. Поки війни не було, то [міжетнічної] різниці не було» – зазначає Ганна Кухарчук із с. Княгинінок.\",\n",
    "    \"Про свій досвід взаємодії з євреями Антоніна Гук із с. Зелений Дуб пригадує наступне: «Жиди приходили до нас додому. Мама хотіли їм квасолі дати, а він каже «ми квасолі не їмо». Це так той єврей сказав. А чому він приходив, то я не знаю, мабуть через якусь потребу. Такі ж люди були, як і ми…»\",\n",
    "    \"Потім він по-польськи сказав “Nemá nič”» – розповідає Галина Береза з с. Коршів Волинської області\", # non-ukrainian phrases\n",
    "    \"Інший календар, яким часто послуговуються оповідачі – релігійний. Оскільки більшість етнічних українців Волині належать до православної конфесії, найважливішими святами для них є Різдво (7 січня), Водохреща (19 січня), Стрітення (15 лютого), Благовіщеня (7 квітня), Великдень (дата щороку змінюється), Трійця (через 50 днів після Великодня), Святих Петра і Павла (12 липня), Спаса (19 серпня) тощо. Всі ці свята відзначаються згідно юліанського (а не григоріанського) календаря.\", # not a real entities\n",
    "    \"Людей не понищили, отак прийшли й зайняли територію. Батькам не було страшно, наш тато ні до кого не ліз, дбали тільки про свою сім’ю й ніхто не зачіпав. У 1939 р. було створено десь 10 чи 11 колгоспів. Бідні люди самі пішли в колгосп. Володимир теж пішов у колгосп. Йому платили по 9 кг. зерна за трудодень. Заробив він десь 40 метрів зерна (приблизно 4 тони)\", # just first name\n",
    "    \"Тоді саме були жнива й Галина їх переховувала в копнах. Вона дуже багато євреїв переховувала…\", # just first name\n",
    "    \"Ядвіга хотіли їм квасолі дати, а він каже «ми квасолі не їмо». Це так той єврей сказав.\", # just first name\n",
    "    \"Цю думку ізраїльського історика цитує Джон-Пол Химка.\", # non-ukrainian name\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4961b14-e642-4b9c-9f75-921da002a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Projects/ua-testimonies/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ukr-models/uk-ner')\n",
    "model = AutoModelForTokenClassification.from_pretrained('ukr-models/uk-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40cf1c6b-acd0-4572-904e-e11cea33e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_predictions(model, tokenizer, texts, is_split_to_words=False, device='cpu'):\n",
    "    words_res = []\n",
    "    y_res = []\n",
    "\n",
    "    if not is_split_to_words:\n",
    "        texts = [tokenize_uk.tokenize_words(text) for text in texts]\n",
    "\n",
    "    for text in texts:\n",
    "        size = len(text)\n",
    "        idx_list = [idx + 1 for idx, val in enumerate(text) if val in ['.', '?', '!']]\n",
    "        if len(idx_list):\n",
    "            sents = [text[i: j] for i, j in zip([0] + idx_list, idx_list + ([size] if idx_list[-1] != size else []))]\n",
    "        else:\n",
    "            sents = [text]\n",
    "\n",
    "        y_res_x = []\n",
    "        words_res_x = []\n",
    "        for sent_tokens in sents:\n",
    "            tokenized_inputs = [101]\n",
    "            word_ids = [None]\n",
    "            for word_id, word in enumerate(sent_tokens):\n",
    "                word_tokens = tokenizer.encode(word)[1:-1]\n",
    "                tokenized_inputs += word_tokens\n",
    "                word_ids += [word_id]*len(word_tokens)\n",
    "            tokenized_inputs = tokenized_inputs[:(tokenizer.model_max_length-1)]\n",
    "            word_ids = word_ids[:(tokenizer.model_max_length-1)]\n",
    "            tokenized_inputs += [102]\n",
    "            word_ids += [None]\n",
    "\n",
    "            torch_tokenized_inputs = torch.tensor(tokenized_inputs).unsqueeze(0)\n",
    "            torch_attention_mask = torch.ones(torch_tokenized_inputs.shape)\n",
    "            predictions = model.forward(input_ids=torch_tokenized_inputs.to(device), attention_mask=torch_attention_mask.to(device))\n",
    "            predictions = torch.argmax(predictions.logits.squeeze(), axis=1).numpy()\n",
    "            predictions = [model.config.id2label[i] for i in predictions]\n",
    "\n",
    "            previous_word_idx = None\n",
    "            sent_words = []\n",
    "            predictions_words = []\n",
    "            word_tokens = []\n",
    "            first_pred = None\n",
    "            for i, word_idx in enumerate(word_ids):\n",
    "                if word_idx != previous_word_idx:\n",
    "                    sent_words.append(tokenizer.decode(word_tokens))\n",
    "                    word_tokens = [tokenized_inputs[i]]\n",
    "                    predictions_words.append(first_pred)\n",
    "                    first_pred = predictions[i]\n",
    "                else:\n",
    "                    word_tokens.append(tokenized_inputs[i])      \n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "            words_res_x.extend(sent_words[1:])\n",
    "            y_res_x.extend(predictions_words[1:])\n",
    "\n",
    "        words_res.append(words_res_x)\n",
    "        y_res.append(y_res_x)\n",
    "\n",
    "    return words_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9581d68-ee5e-4b47-99bb-284ff921ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexize(k=8):\n",
    "    return \"ID_\" + \"\".join(random.choices(string.ascii_uppercase, k=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6504ac0-e816-4691-818e-de13f3cb9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_post_net = get_word_predictions(model, tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d21e5059-396d-4db5-8590-fe357e0dab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "entities = {}\n",
    "persons = [\"B-PER\", \"I-PER\"]\n",
    "locations = [\"B-LOC\", \"I-LOC\"]\n",
    "for i, txt in enumerate(text):\n",
    "    output.append(\"\")\n",
    "    words_entities_pairs = list(zip(words_post_net[0][i], words_post_net[1][i]))\n",
    "    for pair in words_entities_pairs:\n",
    "        # replace entity with an identifier\n",
    "        if pair[1] in persons or pair[1] in locations:\n",
    "            idx = indexize()\n",
    "            while idx in entities:\n",
    "                idx = indexize()\n",
    "            word = idx\n",
    "            entities[idx] = pair[0]\n",
    "        else:\n",
    "            word = pair[0]\n",
    "\n",
    "        # add a word (anonymized or otherwise) to the output\n",
    "        if word in string.punctuation or len(output[i]) == 0:\n",
    "            output[i] += word\n",
    "        else:\n",
    "            output[i] += \" \" + word            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e5965cc-4398-43b9-b72f-a844aff89215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['« У селі жили і поляки, і українці. Мамина рідна сестра вийшла заміж за поляка. Там вони живуть досі ті мої двоюрідні сестри. Батькові сестри також повиходили заміж за поляків. Поки війни не було, то[ міжетнічної] різниці не було » – зазначає ID_HYOTWUHT ID_PZJLYMRB із с. Княгинінок.',\n",
       " 'Про свій досвід взаємодії з євреями ID_JTMWOMGL ID_KFYRAHYV із с. Зелений ID_PQZMVBHG пригадує наступне: « Жиди приходили до нас додому. Мама хотіли їм квасолі дати, а він каже « ми квасолі не їмо ». Це так той єврей сказав. А чому він приходив, то я не знаю, мабуть через якусь потребу. Такі ж люди були, як і ми ... »',\n",
       " 'Потім він по- польськи сказав “ Nemá ni<unk> ” » – розповідає ID_IAFOUGHU ID_OXAKLUOL з с. Коршів ID_UTMXZWXN ID_AXVOUTSP',\n",
       " 'Інший календар, яким часто послуговуються оповідачі – релігійний. Оскільки більшість етнічних українців ID_ITPTKBZH належать до православної конфесії, найважливішими святами для них є Різдво( 7 січня), Водохреща( 19 січня), Стрітення( 15 лютого), Благовіщеня( 7 квітня), Великдень( дата щороку змінюється), Трійця( через 50 днів після Великодня), Святих Петра і ID_JUFWQVUG( 12 липня), Спаса( 19 серпня) тощо. Всі ці свята відзначаються згідно юліанського( а не григоріанського) календаря.',\n",
       " 'Людей не понищили, отак прийшли й зайняли територію. Батькам не було страшно, наш тато ні до кого не ліз, дбали тільки про свою сім’ю й ніхто не зачіпав. У 1939 р. було створено десь 10 чи 11 колгоспів. Бідні люди самі пішли в колгосп. ID_JVTYBLWE теж пішов у колгосп. Йому платили по 9 кг. зерна за трудодень. Заробив він десь 40 метрів зерна( приблизно 4 тони)',\n",
       " 'Тоді саме були жнива й ID_UMOTYFRT їх переховувала в копнах. Вона дуже багато євреїв переховувала ...',\n",
       " 'Ядвіга хотіли їм квасолі дати, а він каже « ми квасолі не їмо ». Це так той єврей сказав.',\n",
       " 'Цю думку ізраїльського історика цитує ID_OGMHJUCB ID_ASRUHJWW ID_TMUAIONP ID_ZUMFKMFY.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce41d4d8-dd51-4737-a126-4f08ff07f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': np.float32(0.9999862), 'index': 74, 'word': '▁Ган', 'start': 240, 'end': 244}, {'entity': 'B-PER', 'score': np.float32(0.9999864), 'index': 75, 'word': 'на', 'start': 244, 'end': 246}, {'entity': 'I-PER', 'score': np.float32(0.9999951), 'index': 76, 'word': '▁Ку', 'start': 246, 'end': 249}, {'entity': 'I-PER', 'score': np.float32(0.9999951), 'index': 77, 'word': 'хар', 'start': 249, 'end': 252}, {'entity': 'I-PER', 'score': np.float32(0.99999523), 'index': 78, 'word': 'чук', 'start': 252, 'end': 255}]\n",
      "[{'entity': 'B-PER', 'score': np.float32(0.9999908), 'index': 9, 'word': '▁Антон', 'start': 35, 'end': 41}, {'entity': 'B-PER', 'score': np.float32(0.99999), 'index': 10, 'word': 'іна', 'start': 41, 'end': 44}, {'entity': 'I-PER', 'score': np.float32(0.9999956), 'index': 11, 'word': '▁Гу', 'start': 44, 'end': 47}, {'entity': 'I-PER', 'score': np.float32(0.9999958), 'index': 12, 'word': 'к', 'start': 47, 'end': 48}, {'entity': 'B-PER', 'score': np.float32(0.9988746), 'index': 18, 'word': '▁Дуб', 'start': 62, 'end': 66}]\n",
      "[{'entity': 'B-PER', 'score': np.float32(0.9999858), 'index': 19, 'word': '▁Гали', 'start': 53, 'end': 58}, {'entity': 'B-PER', 'score': np.float32(0.99998546), 'index': 20, 'word': 'на', 'start': 58, 'end': 60}, {'entity': 'I-PER', 'score': np.float32(0.99999547), 'index': 21, 'word': '▁Берез', 'start': 60, 'end': 66}, {'entity': 'I-PER', 'score': np.float32(0.99999547), 'index': 22, 'word': 'а', 'start': 66, 'end': 67}, {'entity': 'B-LOC', 'score': np.float32(0.9996674), 'index': 29, 'word': '▁Волин', 'start': 79, 'end': 85}, {'entity': 'B-LOC', 'score': np.float32(0.99968076), 'index': 30, 'word': 'ської', 'start': 85, 'end': 90}, {'entity': 'I-LOC', 'score': np.float32(0.9998795), 'index': 31, 'word': '▁області', 'start': 90, 'end': 98}]\n",
      "[{'entity': 'B-LOC', 'score': np.float32(0.9999845), 'index': 24, 'word': '▁Волин', 'start': 103, 'end': 109}, {'entity': 'B-LOC', 'score': np.float32(0.9999857), 'index': 25, 'word': 'і', 'start': 109, 'end': 110}, {'entity': 'I-PER', 'score': np.float32(0.5188713), 'index': 93, 'word': '▁Петра', 'start': 348, 'end': 354}, {'entity': 'I-PER', 'score': np.float32(0.5356759), 'index': 95, 'word': '▁Павла', 'start': 356, 'end': 362}]\n",
      "[{'entity': 'B-PER', 'score': np.float32(0.9950376), 'index': 79, 'word': '▁Володимир', 'start': 235, 'end': 245}]\n",
      "[{'entity': 'B-PER', 'score': np.float32(0.99998343), 'index': 8, 'word': '▁Гали', 'start': 22, 'end': 27}, {'entity': 'B-PER', 'score': np.float32(0.99998164), 'index': 9, 'word': 'на', 'start': 27, 'end': 29}]\n",
      "[]\n",
      "[{'entity': 'B-PER', 'score': np.float32(0.9999424), 'index': 14, 'word': '▁Джон', 'start': 37, 'end': 42}, {'entity': 'B-PER', 'score': np.float32(0.79852545), 'index': 15, 'word': '-', 'start': 42, 'end': 43}, {'entity': 'B-PER', 'score': np.float32(0.9931471), 'index': 16, 'word': 'По', 'start': 43, 'end': 45}, {'entity': 'B-PER', 'score': np.float32(0.7034347), 'index': 17, 'word': 'л', 'start': 45, 'end': 46}, {'entity': 'I-PER', 'score': np.float32(0.99998415), 'index': 18, 'word': '▁Хи', 'start': 46, 'end': 49}, {'entity': 'I-PER', 'score': np.float32(0.99998724), 'index': 19, 'word': 'м', 'start': 49, 'end': 50}, {'entity': 'I-PER', 'score': np.float32(0.99998665), 'index': 20, 'word': 'ка', 'start': 50, 'end': 52}]\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "for txt in text:\n",
    "    print(ner(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ed5d5-ab6b-4ca6-a99f-0b6a466729f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
